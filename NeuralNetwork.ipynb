{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coCWqLxU2lMo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Подключаем необходимые модули"
   ],
   "id": "coCWqLxU2lMo"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y7AlJOfC29Q0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (0.17.1)\r\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow_addons) (2.13.3)\r\n",
      "Requirement already satisfied: packaging in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow_addons) (21.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from packaging->tensorflow_addons) (3.0.9)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.2.1 is available.\r\n",
      "You should consider upgrading via the '/Users/imac-5k-6/Python/doctr/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Requirement already satisfied: tensorflow in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (2.9.1)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (3.19.4)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (3.7.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.47.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (4.3.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.12)\r\n",
      "Requirement already satisfied: setuptools in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (60.2.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.1.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.1.2)\r\n",
      "Requirement already satisfied: packaging in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (21.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (0.26.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (14.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.23.0)\r\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (2.9.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.1.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (2.9.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (2.9.0)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.25.11)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/imac-5k-6/Python/doctr/venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.2.1 is available.\r\n",
      "You should consider upgrading via the '/Users/imac-5k-6/Python/doctr/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n",
    "!pip install tensorflow"
   ],
   "id": "y7AlJOfC29Q0"
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/lyftzeigen/SemanticSegmentationLesson.git"
   ],
   "metadata": {
    "id": "iCaLPVesuaSm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "iCaLPVesuaSm",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SemanticSegmentationLesson'...\r\n",
      "remote: Enumerating objects: 2563, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (9/9), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\r\n",
      "remote: Total 2563 (delta 1), reused 8 (delta 1), pack-reused 2554\u001B[K\r\n",
      "\u001B[KReceiving objects: 100% (2563/2563), 284.44 MiB | 9.94 MiB/s, done.\r\n",
      "\u001B[KResolving deltas: 100% (1/1), done.\r\n",
      "\u001B[KUpdating files: 100% (2557/2557), done.\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e8f0321d-9fcb-4e27-a8d9-e9986ae56179",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_addons\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfa\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m measure\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m imread, imsave, imshow\n",
      "File \u001B[0;32m~/Python/doctr/venv/lib/python3.9/site-packages/tensorflow_addons/__init__.py:18\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"Useful extra functionality for TensorFlow maintained by SIG-addons.\"\"\"\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_addons\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensure_tf_install\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _check_tf_version\n\u001B[0;32m---> 18\u001B[0m \u001B[43m_check_tf_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Local project imports\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_addons\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n",
      "File \u001B[0;32m~/Python/doctr/venv/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:36\u001B[0m, in \u001B[0;36m_check_tf_version\u001B[0;34m()\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_tf_version\u001B[39m():\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;124;03m\"\"\"Warn the user if the version of TensorFlow used is not supported.\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \n\u001B[1;32m     32\u001B[0m \u001B[38;5;124;03m    This is not a check for custom ops compatibility. This check only ensure that\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m    we support this TensorFlow version if the user uses only Addons' Python code.\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdev\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__version__\u001B[49m:\n\u001B[1;32m     37\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m     38\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are currently using a nightly version of TensorFlow (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m). \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTensorFlow Addons offers no support for the nightly versions of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[1;32m     44\u001B[0m         )\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from skimage import measure\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import dilation, disk\n",
    "from skimage.draw import polygon, polygon_perimeter\n",
    "\n",
    "print(f'Tensorflow version {tf.__version__}')\n",
    "print(f'GPU is {\"ON\" if tf.config.list_physical_devices(\"GPU\") else \"OFF\" }')"
   ],
   "id": "e8f0321d-9fcb-4e27-a8d9-e9986ae56179"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9e5c5b4-6daa-4dee-8be6-dd67343bf3d3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Подготовим набор данных для обучения"
   ],
   "id": "e9e5c5b4-6daa-4dee-8be6-dd67343bf3d3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "82be98ae-bc6e-4d49-b205-db5130879caa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = 8\n",
    "\n",
    "COLORS = ['black', 'red', 'lime',\n",
    "          'blue', 'orange', 'pink',\n",
    "          'cyan', 'magenta']\n",
    "\n",
    "SAMPLE_SIZE = (256, 256)\n",
    "\n",
    "OUTPUT_SIZE = (1080, 1920)"
   ],
   "id": "82be98ae-bc6e-4d49-b205-db5130879caa"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "500caf45-f2b9-48af-8f91-7d31d44ec266",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_images(image, mask):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, OUTPUT_SIZE)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    mask = tf.io.read_file(mask)\n",
    "    mask = tf.io.decode_png(mask)\n",
    "    mask = tf.image.rgb_to_grayscale(mask)\n",
    "    mask = tf.image.resize(mask, OUTPUT_SIZE)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    for i in range(CLASSES):\n",
    "        masks.append(tf.where(tf.equal(mask, float(i)), 1.0, 0.0))\n",
    "    \n",
    "    masks = tf.stack(masks, axis=2)\n",
    "    masks = tf.reshape(masks, OUTPUT_SIZE + (CLASSES,))\n",
    "\n",
    "    return image, masks\n",
    "\n",
    "def augmentate_images(image, masks):   \n",
    "    random_crop = tf.random.uniform((), 0.3, 1)\n",
    "    image = tf.image.central_crop(image, random_crop)\n",
    "    masks = tf.image.central_crop(masks, random_crop)\n",
    "    \n",
    "    random_flip = tf.random.uniform((), 0, 1)    \n",
    "    if random_flip >= 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        masks = tf.image.flip_left_right(masks)\n",
    "    \n",
    "    image = tf.image.resize(image, SAMPLE_SIZE)\n",
    "    masks = tf.image.resize(masks, SAMPLE_SIZE)\n",
    "    \n",
    "    return image, masks"
   ],
   "id": "500caf45-f2b9-48af-8f91-7d31d44ec266"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1d6ac3f3-17b7-4fe5-9622-c7d82fbdaff2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSemanticSegmentationLesson/dataset/images/*.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      2\u001B[0m masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSemanticSegmentationLesson/dataset/masks/*.png\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m images_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices(images)\n\u001B[1;32m      5\u001B[0m masks_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices(masks)\n\u001B[1;32m      7\u001B[0m dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip((images_dataset, masks_dataset))\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "images = sorted(glob.glob('SemanticSegmentationLesson/dataset/images/*.jpg'))\n",
    "masks = sorted(glob.glob('SemanticSegmentationLesson/dataset/masks/*.png'))\n",
    "\n",
    "images_dataset = tf.data.Dataset.from_tensor_slices(images)\n",
    "masks_dataset = tf.data.Dataset.from_tensor_slices(masks)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((images_dataset, masks_dataset))\n",
    "\n",
    "dataset = dataset.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.repeat(60)\n",
    "dataset = dataset.map(augmentate_images, num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "id": "1d6ac3f3-17b7-4fe5-9622-c7d82fbdaff2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cd0f38c-d6f6-48f6-842e-d392ecf6a923",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Посмотрим на содержимое набора данных"
   ],
   "id": "0cd0f38c-d6f6-48f6-842e-d392ecf6a923"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe418202-ca78-4f37-a5e0-4a195fb9a8b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_and_masks = list(dataset.take(5))\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 5, figsize=(15, 5), dpi=125)\n",
    "\n",
    "for i, (image, masks) in enumerate(images_and_masks):\n",
    "    ax[0, i].set_title('Image')\n",
    "    ax[0, i].set_axis_off()\n",
    "    ax[0, i].imshow(image)\n",
    "        \n",
    "    ax[1, i].set_title('Mask')\n",
    "    ax[1, i].set_axis_off()    \n",
    "    ax[1, i].imshow(image/1.5)\n",
    "   \n",
    "    for channel in range(CLASSES):\n",
    "        contours = measure.find_contours(np.array(masks[:,:,channel]))\n",
    "        for contour in contours:\n",
    "            ax[1, i].plot(contour[:, 1], contour[:, 0], linewidth=1, color=COLORS[channel])\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "fe418202-ca78-4f37-a5e0-4a195fb9a8b2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5a2c4bf-74e0-41de-86c6-e89687ef3ca4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Разделим набор данных на обучающий и проверочный"
   ],
   "id": "a5a2c4bf-74e0-41de-86c6-e89687ef3ca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd9e3f67-5f19-48f3-9a9f-09660b64d49a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.take(2000).cache()\n",
    "test_dataset = dataset.skip(2000).take(100).cache()\n",
    " \n",
    "train_dataset = train_dataset.batch(16)\n",
    "test_dataset = test_dataset.batch(16)"
   ],
   "id": "cd9e3f67-5f19-48f3-9a9f-09660b64d49a"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "482b3f41-5324-41e1-944d-809ec06ee959",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обозначим основные блоки модели"
   ],
   "id": "482b3f41-5324-41e1-944d-809ec06ee959"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69b6dcd3-d04f-4c6c-bca7-7315df18ff4b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def input_layer():\n",
    "    return tf.keras.layers.Input(shape=SAMPLE_SIZE + (3,))\n",
    "\n",
    "def downsample_block(filters, size, batch_norm=True):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    \n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if batch_norm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "def upsample_block(filters, size, dropout=False):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    \n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                                        kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    if dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result\n",
    "\n",
    "def output_layer(size):\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    return tf.keras.layers.Conv2DTranspose(CLASSES, size, strides=2, padding='same',\n",
    "                                           kernel_initializer=initializer, activation='sigmoid')"
   ],
   "id": "69b6dcd3-d04f-4c6c-bca7-7315df18ff4b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4ea1c64-11ac-485c-bcde-b4059bd74edc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Построим U-NET подобную архитектуру"
   ],
   "id": "a4ea1c64-11ac-485c-bcde-b4059bd74edc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4f2ece8-75f3-46b9-8918-f4034f223b40",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inp_layer = input_layer()\n",
    "\n",
    "downsample_stack = [\n",
    "    downsample_block(64, 4, batch_norm=False),\n",
    "    downsample_block(128, 4),\n",
    "    downsample_block(256, 4),\n",
    "    downsample_block(512, 4),\n",
    "    downsample_block(512, 4),\n",
    "    downsample_block(512, 4),\n",
    "    downsample_block(512, 4),\n",
    "]\n",
    "\n",
    "upsample_stack = [\n",
    "    upsample_block(512, 4, dropout=True),\n",
    "    upsample_block(512, 4, dropout=True),\n",
    "    upsample_block(512, 4, dropout=True),\n",
    "    upsample_block(256, 4),\n",
    "    upsample_block(128, 4),\n",
    "    upsample_block(64, 4)\n",
    "]\n",
    "\n",
    "out_layer = output_layer(4)\n",
    "\n",
    "# Реализуем skip connections\n",
    "x = inp_layer\n",
    "\n",
    "downsample_skips = []\n",
    "\n",
    "for block in downsample_stack:\n",
    "    x = block(x)\n",
    "    downsample_skips.append(x)\n",
    "    \n",
    "downsample_skips = reversed(downsample_skips[:-1])\n",
    "\n",
    "for up_block, down_block in zip(upsample_stack, downsample_skips):\n",
    "    x = up_block(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, down_block])\n",
    "\n",
    "out_layer = out_layer(x)\n",
    "\n",
    "unet_like = tf.keras.Model(inputs=inp_layer, outputs=out_layer)\n",
    "\n",
    "tf.keras.utils.plot_model(unet_like, show_shapes=True, dpi=72)"
   ],
   "id": "a4f2ece8-75f3-46b9-8918-f4034f223b40"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b67f732f-120b-49a8-bc7c-304709f12db5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Определим метрики и функции потерь"
   ],
   "id": "b67f732f-120b-49a8-bc7c-304709f12db5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a6aa6d8-f478-4d28-acfb-c217c112c381",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dice_mc_metric(a, b):\n",
    "    a = tf.unstack(a, axis=3)\n",
    "    b = tf.unstack(b, axis=3)\n",
    "    \n",
    "    dice_summ = 0\n",
    "    \n",
    "    for i, (aa, bb) in enumerate(zip(a, b)):\n",
    "        numenator = 2 * tf.math.reduce_sum(aa * bb) + 1\n",
    "        denomerator = tf.math.reduce_sum(aa + bb) + 1\n",
    "        dice_summ += numenator / denomerator\n",
    "        \n",
    "    avg_dice = dice_summ / CLASSES\n",
    "    \n",
    "    return avg_dice\n",
    "\n",
    "def dice_mc_loss(a, b):\n",
    "    return 1 - dice_mc_metric(a, b)\n",
    "\n",
    "def dice_bce_mc_loss(a, b):\n",
    "    return 0.3 * dice_mc_loss(a, b) + tf.keras.losses.binary_crossentropy(a, b)"
   ],
   "id": "9a6aa6d8-f478-4d28-acfb-c217c112c381"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b439664c-71f0-49ac-a462-4d60cc5ec77c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Компилируем модель"
   ],
   "id": "b439664c-71f0-49ac-a462-4d60cc5ec77c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa219c12-c5af-4065-8660-fb8d6aa7d2a1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unet_like.compile(optimizer='adam', loss=[dice_bce_mc_loss], metrics=[dice_mc_metric])"
   ],
   "id": "fa219c12-c5af-4065-8660-fb8d6aa7d2a1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75bfd329-31b4-4200-8282-1cb066d52b83",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучаем нейронную сеть и сохраняем результат"
   ],
   "id": "75bfd329-31b4-4200-8282-1cb066d52b83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "215d6d6e-9c85-49e0-8601-37d90d7eb7cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history_dice = unet_like.fit(train_dataset, validation_data=test_dataset, epochs=25, initial_epoch=0)\n",
    "\n",
    "unet_like.save_weights('SemanticSegmentationLesson/networks/unet_like')"
   ],
   "id": "215d6d6e-9c85-49e0-8601-37d90d7eb7cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "311e395e-5465-4507-a75c-7ea95dc19e69",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Загрузим модель"
   ],
   "id": "311e395e-5465-4507-a75c-7ea95dc19e69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67f70032-8e6d-4b3f-b078-f227bf90ab0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unet_like.load_weights('SemanticSegmentationLesson/networks/unet_like')"
   ],
   "id": "67f70032-8e6d-4b3f-b078-f227bf90ab0c"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e978c692-4136-419b-9365-e5fbf98bbf50",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Проверим работу сети на всех кадрах из видео"
   ],
   "id": "e978c692-4136-419b-9365-e5fbf98bbf50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59b67499-d8a3-42a1-a990-b2b7184ad75c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rgb_colors = [\n",
    "    (0,   0,   0),\n",
    "    (255, 0,   0),\n",
    "    (0,   255, 0),\n",
    "    (0,   0,   255),\n",
    "    (255, 165, 0),\n",
    "    (255, 192, 203),\n",
    "    (0,   255, 255),\n",
    "    (255, 0,   255)\n",
    "]\n",
    "\n",
    "frames = sorted(glob.glob('SemanticSegmentationLesson/videos/original_video/*.jpg'))\n",
    "\n",
    "for filename in frames:\n",
    "    frame = imread(filename)\n",
    "    sample = resize(frame, SAMPLE_SIZE)\n",
    "    \n",
    "    predict = unet_like.predict(sample.reshape((1,) +  SAMPLE_SIZE + (3,)))\n",
    "    predict = predict.reshape(SAMPLE_SIZE + (CLASSES,))\n",
    "        \n",
    "    scale = frame.shape[0] / SAMPLE_SIZE[0], frame.shape[1] / SAMPLE_SIZE[1]\n",
    "    \n",
    "    frame = (frame / 1.5).astype(np.uint8)\n",
    "    \n",
    "    for channel in range(1, CLASSES): \n",
    "        contour_overlay = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "        contours = measure.find_contours(np.array(predict[:,:,channel]))\n",
    "        \n",
    "        try:\n",
    "            for contour in contours:\n",
    "                rr, cc = polygon_perimeter(contour[:, 0] * scale[0],\n",
    "                                           contour[:, 1] * scale[1],\n",
    "                                           shape=contour_overlay.shape)\n",
    "                \n",
    "                contour_overlay[rr, cc] = 1        \n",
    "            \n",
    "            contour_overlay = dilation(contour_overlay, disk(1))\n",
    "            frame[contour_overlay == 1] = rgb_colors[channel]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    imsave(f'SemanticSegmentationLesson/videos/processed/{os.path.basename(filename)}', frame)"
   ],
   "id": "59b67499-d8a3-42a1-a990-b2b7184ad75c"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNetwork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}